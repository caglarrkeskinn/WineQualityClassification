{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe025f4-84ba-493c-adec-92cfaa0c1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce58b98d-aca0-41bb-8227-3411cb135846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [4, 3, 2, 1],\n",
    "    [8, 6, 3, 2],\n",
    "    [4, 4, 4, 4]\n",
    "])\n",
    "\n",
    "y = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "003d2077-4b53-4bf0-94a0-e83c7842b067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605e9b98-7843-436f-968a-34497bd3855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5addbf-5074-4aa6-a155-2cd300be27ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.666666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1971838d-42ba-418f-855c-c41b63b86c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 * model.coef_).sum() + model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb2eb8fc-7b33-458e-8e22-9c1a1afa3438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Ordinary least squares Linear Regression.\n",
       "\n",
       "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
       "to minimize the residual sum of squares between the observed targets in\n",
       "the dataset, and the targets predicted by the linear approximation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "fit_intercept : bool, default=True\n",
       "    Whether to calculate the intercept for this model. If set\n",
       "    to False, no intercept will be used in calculations\n",
       "    (i.e. data is expected to be centered).\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If True, X will be copied; else, it may be overwritten.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to use for the computation. This will only provide\n",
       "    speedup in case of sufficiently large problems, that is if firstly\n",
       "    `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
       "    to `True`. ``None`` means 1 unless in a\n",
       "    :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
       "    processors. See :term:`Glossary <n_jobs>` for more details.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive. This\n",
       "    option is only supported for dense arrays.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
       "    Estimated coefficients for the linear regression problem.\n",
       "    If multiple targets are passed during the fit (y 2D), this\n",
       "    is a 2D array of shape (n_targets, n_features), while if only\n",
       "    one target is passed, this is a 1D array of length n_features.\n",
       "\n",
       "rank_ : int\n",
       "    Rank of matrix `X`. Only available when `X` is dense.\n",
       "\n",
       "singular_ : array of shape (min(X, y),)\n",
       "    Singular values of `X`. Only available when `X` is dense.\n",
       "\n",
       "intercept_ : float or array of shape (n_targets,)\n",
       "    Independent term in the linear model. Set to 0.0 if\n",
       "    `fit_intercept = False`.\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Ridge : Ridge regression addresses some of the\n",
       "    problems of Ordinary Least Squares by imposing a penalty on the\n",
       "    size of the coefficients with l2 regularization.\n",
       "Lasso : The Lasso is a linear model that estimates\n",
       "    sparse coefficients with l1 regularization.\n",
       "ElasticNet : Elastic-Net is a linear regression\n",
       "    model trained with both l1 and l2 -norm regularization of the\n",
       "    coefficients.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "From the implementation point of view, this is just plain Ordinary\n",
       "Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
       "(scipy.optimize.nnls) wrapped as a predictor object.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LinearRegression\n",
       ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
       ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
       ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
       ">>> reg = LinearRegression().fit(X, y)\n",
       ">>> reg.score(X, y)\n",
       "1.0\n",
       ">>> reg.coef_\n",
       "array([1., 2.])\n",
       ">>> reg.intercept_\n",
       "3.0...\n",
       ">>> reg.predict(np.array([[3, 5]]))\n",
       "array([16.])\n",
       "\u001b[0;31mFile:\u001b[0m           /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_base.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc902b62-fb9d-43b7-a374-1080e170fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "480fc3b8-c9bd-4b9a-9fd2-c07811726d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlapack_driver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Compute least-squares solution to equation Ax = b.\n",
       "\n",
       "Compute a vector x such that the 2-norm ``|b - A x|`` is minimized.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : (M, N) array_like\n",
       "    Left-hand side array\n",
       "b : (M,) or (M, K) array_like\n",
       "    Right hand side array\n",
       "cond : float, optional\n",
       "    Cutoff for 'small' singular values; used to determine effective\n",
       "    rank of a. Singular values smaller than\n",
       "    ``cond * largest_singular_value`` are considered zero.\n",
       "overwrite_a : bool, optional\n",
       "    Discard data in `a` (may enhance performance). Default is False.\n",
       "overwrite_b : bool, optional\n",
       "    Discard data in `b` (may enhance performance). Default is False.\n",
       "check_finite : bool, optional\n",
       "    Whether to check that the input matrices contain only finite numbers.\n",
       "    Disabling may give a performance gain, but may result in problems\n",
       "    (crashes, non-termination) if the inputs do contain infinities or NaNs.\n",
       "lapack_driver : str, optional\n",
       "    Which LAPACK driver is used to solve the least-squares problem.\n",
       "    Options are ``'gelsd'``, ``'gelsy'``, ``'gelss'``. Default\n",
       "    (``'gelsd'``) is a good choice.  However, ``'gelsy'`` can be slightly\n",
       "    faster on many problems.  ``'gelss'`` was used historically.  It is\n",
       "    generally slow but uses less memory.\n",
       "\n",
       "    .. versionadded:: 0.17.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "x : (N,) or (N, K) ndarray\n",
       "    Least-squares solution.\n",
       "residues : (K,) ndarray or float\n",
       "    Square of the 2-norm for each column in ``b - a x``, if ``M > N`` and\n",
       "    ``ndim(A) == n`` (returns a scalar if ``b`` is 1-D). Otherwise a\n",
       "    (0,)-shaped array is returned.\n",
       "rank : int\n",
       "    Effective rank of `a`.\n",
       "s : (min(M, N),) ndarray or None\n",
       "    Singular values of `a`. The condition number of ``a`` is\n",
       "    ``s[0] / s[-1]``.\n",
       "\n",
       "Raises\n",
       "------\n",
       "LinAlgError\n",
       "    If computation does not converge.\n",
       "\n",
       "ValueError\n",
       "    When parameters are not compatible.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "scipy.optimize.nnls : linear least squares with non-negativity constraint\n",
       "\n",
       "Notes\n",
       "-----\n",
       "When ``'gelsy'`` is used as a driver, `residues` is set to a (0,)-shaped\n",
       "array and `s` is always ``None``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from scipy.linalg import lstsq\n",
       ">>> import matplotlib.pyplot as plt\n",
       "\n",
       "Suppose we have the following data:\n",
       "\n",
       ">>> x = np.array([1, 2.5, 3.5, 4, 5, 7, 8.5])\n",
       ">>> y = np.array([0.3, 1.1, 1.5, 2.0, 3.2, 6.6, 8.6])\n",
       "\n",
       "We want to fit a quadratic polynomial of the form ``y = a + b*x**2``\n",
       "to this data.  We first form the \"design matrix\" M, with a constant\n",
       "column of 1s and a column containing ``x**2``:\n",
       "\n",
       ">>> M = x[:, np.newaxis]**[0, 2]\n",
       ">>> M\n",
       "array([[  1.  ,   1.  ],\n",
       "       [  1.  ,   6.25],\n",
       "       [  1.  ,  12.25],\n",
       "       [  1.  ,  16.  ],\n",
       "       [  1.  ,  25.  ],\n",
       "       [  1.  ,  49.  ],\n",
       "       [  1.  ,  72.25]])\n",
       "\n",
       "We want to find the least-squares solution to ``M.dot(p) = y``,\n",
       "where ``p`` is a vector with length 2 that holds the parameters\n",
       "``a`` and ``b``.\n",
       "\n",
       ">>> p, res, rnk, s = lstsq(M, y)\n",
       ">>> p\n",
       "array([ 0.20925829,  0.12013861])\n",
       "\n",
       "Plot the data and the fitted curve.\n",
       "\n",
       ">>> plt.plot(x, y, 'o', label='data')\n",
       ">>> xx = np.linspace(0, 9, 101)\n",
       ">>> yy = p[0] + p[1]*xx**2\n",
       ">>> plt.plot(xx, yy, label='least squares fit, $y = a + bx^2$')\n",
       ">>> plt.xlabel('x')\n",
       ">>> plt.ylabel('y')\n",
       ">>> plt.legend(framealpha=1, shadow=True)\n",
       ">>> plt.grid(alpha=0.25)\n",
       ">>> plt.show()\n",
       "\u001b[0;31mFile:\u001b[0m      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/linalg/_basic.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8285baf-dbc9-4ec1-94cc-a2c3c810edb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
